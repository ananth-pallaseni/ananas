#!/usr/bin/env bash
#
# Copyright 2015 Frank Austin Nothaft
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Figure out where ANANAS is installed
ANANAS_REPO="$(cd `dirname $0`/..; pwd)"

CLASSPATH=$("$ANANAS_REPO"/bin/compute-ananas-classpath.sh)
ANANAS_JARS=$("$ANANAS_REPO"/bin/compute-ananas-jars.sh)

# Find the ANANAS CLI jar
num_versions=$(ls "$ANANAS_REPO"/target/appassembler/repo/net/fnothaft/ananas | wc -l)
if [ "$num_versions" -eq "0" ]; then
  echo "Failed to find ananas jar in $ANANAS_REPO/target/appassembler/repo/net/fnothaft/ananas"
  echo "You need to build ananas before running this program."
  exit 1
fi
if [ "$num_versions" -gt "1" ]; then
  versions_list=$(ls "$ANANAS_REPO"/target/appassembler/repo/net/fnothaft/ananas)
  echo "Found multiple ananas versions in $ANANAS_REPO/target/appassembler/repo/net/fnothaft/ananas:"
  echo "$versions_list"
  echo "Please remove all but one."
  exit 1
fi
ANANAS_CLI_JAR=$(ls "$ANANAS_REPO"/target/appassembler/repo/net/fnothaft/ananas/*/ananas-*.jar)

if [ -z "$SPARK_HOME" ]; then
  echo "Attempting to use 'spark-submit' on default path; you might need to set SPARK_HOME"
  SPARK_SUBMIT=spark-submit
else
  SPARK_SUBMIT="$SPARK_HOME"/bin/spark-submit
fi

# submit the job to Spark
"$SPARK_SUBMIT" \
  --class net.fnothaft.ananas.Ananas \
  --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
  --conf spark.kryo.registrator=org.bdgenomics.adam.serialization.ADAMKryoRegistrator \
  --conf spark.kryoserializer.buffer.mb=4 \
  --conf spark.kryo.referenceTracking=true \
  --conf spark.executor.memory=${ANANAS_EXECUTOR_MEMORY:-55g} \
  ${ANANAS_OPTS:- } \
  --driver-memory ${ANANAS_DRIVER_MEMORY:-55g} \
  --jars "$ANANAS_JARS" \
  "$ANANAS_CLI_JAR" \
  "$@"
